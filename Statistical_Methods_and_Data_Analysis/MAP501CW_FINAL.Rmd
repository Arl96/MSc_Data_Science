---
title: "20MAP501_CW Assignment"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# 1. Preamble 

**a. Load in any packages you will use to undertake this coursework, including AmesHousing. Use make_ames() command to create a clean version of the Ames Housing dataset called Ames. (5 points)**

```{r, message=FALSE}
# import relevant packages
library(rio)
library(dplyr)
library(tidyr)
library(ggplot2)
library(pROC)
library(car)
library(nnet)
library(AmesHousing)
library(tidyverse)
library(lme4)
library(caret)
```

```{r}
# create clean ames housing dataset
ames <- make_ames()
```


**b. Import the england-premier-league-players-2018-to-2019-stats.csv dataset as “playerstats”, ensuring that all variables are treated correctly. Where variable names have a space, rename the variables without these. Remove the cases with age<10 Create a new variable, “played”, in playerstats that indicates if a player played greater than 0 minutes or not. Create a new dataset called “football” consisting of only those players that played greater than 0 minutes. Create a new dataset called “footballngk” consisting of those players in “football” who are not goalkeepers. Drop the unused level of “position”. (5 points)**

```{r}
# load in football data
playerstats <- import("england-premier-league-players-2018-to-2019-stats.csv")
```

```{r}
# remove spaces in variables
playerstats$club <- playerstats$`Current Club`
playerstats$`Current Club` <- NULL
```

```{r}
# remove rows where age < 10
playerstats <- playerstats %>%
  filter(age > 10)
```

```{r}
# create 'played' variable
playerstats$played <- (playerstats$minutes_played_overall > 0)
```

```{r}
# create new dataset with only players who played
football <- playerstats %>%
  filter(played==TRUE)
```

```{r}
# create new dataset without goalkeepers
footballngk <- football %>%
  filter(position != "Goalkeeper")
```

```{r, results=FALSE}
# chaneg “position” to factor
footballngk$position<-as.factor(footballngk$position)

# drop the unused level of “position”
footballngk %>% 
  droplevels()
```

```{r}
# check level of goalkeeper has been dropped
levels(footballngk$position)
```


# 2. Linear Regression

**a. By adjusting x axis range and number of bars, create a useful histogram of Lot_Area on the full dataset. Ensure that plot titles and axis labels are clear. Comment on why deleting properties with Lot_Area> 30000 makes sense. Create a new dataset Ames2 consisting only of those properties with lot area <30000. (5 points)**

```{r}
# set global plot theme
old <- theme_set(theme_classic())
theme_set(old)
theme_update(
  panel.grid.major.x = element_blank(), 
  panel.grid.minor.x = element_blank(),
  panel.grid.major.y = element_line(colour = "grey80"), 
  panel.grid.minor.y = element_blank(),
  panel.background   = element_blank(), 
  axis.line.y  = element_blank(),
  axis.line.x  = element_line(colour = "black"),
  axis.ticks.y = element_blank(),
  axis.text.x  = element_text(
                     angle = 0, 
                     hjust = 0.5, 
                     vjust = 0.5))
                     
```

```{r  warning=FALSE, position=0}
# create plot object
p1 <- ames %>% 
  ggplot(
    aes(
      x = Lot_Area
    ))

# make histogram
p1 + geom_histogram(bins=100) +
  # add titles etc
  labs(
    title = "Lot area of properties in the Ames dataset",
    x = "Lot area (square feet)",
    y = "Count"
  ) +
  # improve scaling
  scale_x_continuous(limits = c(0,30000), expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0))
```

Removing properties with lot area < 30000 makes sense because there are few properties with lot area this large, and some of these larger properties have lot areas much larger than 30000. The bulk of the data lies roughly between 0 and 30000, and so including the data out of this range is likely to skew results.

```{r}
# create a new dataset Ames2 consisting only of those properties with lot area <30000
ames2 <- ames %>%
  filter(Lot_Area < 30000)
```



**b. Now remove all cases corresponding to MS_Zoning categories of A_agr (agricultural), C_all (commercial) and I_all (industrial) from the Ames2 dataset. Drop the unused levels from the MS_Zoning variable. (2 points)**

```{r}
# filter cases
ames2 <- ames2[!(ames2$MS_Zoning %in% c("A_agr","C_all","I_all")),]

# drop the unused levels
ames2 <- ames2 %>%
  droplevels()

# check levels have been dropped
levels(ames2$MS_Zoning)
```



**c. Choose an appropriate plot to investigate the relationship between MS_Zoning and Lot_Area in Ames2. (2 points)**


```{r}
# create plot object
p2 <- ames2 %>%
  ggplot(
    mapping = aes(
      x = MS_Zoning,
      y = Lot_Area,
    ),
    width= 2,
    height =2
  )

# add points
p2 + 
  # add box plot
  geom_boxplot(mapping=aes(fill=MS_Zoning), alpha=0.8) +
  # add titles etc
  labs(
    title = "Relationship between zoning and lot area",
    x = "Zone",
    y = "Lot area (square feet)"
  ) +
  # improve scaling
  scale_y_continuous(expand = c(0, 0)) +
  # improve aesthetics
  theme(
    panel.grid.major.x  = element_line(colour = "grey80"),
    axis.line.y  = element_line(colour = "black"),
    legend.position = "none"
  ) +
  # change axis labels
  scale_x_discrete(labels=c("Floating_Village_Residential" = "Floating\nVillage \n Residential",
                            "Residential_High_Density" = "Residential\nHigh\nDensity",
                            "Residential_Low_Density" = "Residential\nLow\nDensity",
                            "Residential_Medium_Density" = "Residential\nMedium\nDensity"))
```

**d. Choose an appropriate plot to investigate the relationship between Gr_Liv_Area and Lot_Area in Ames2. Color points according to the factor MS_Zoning. Ensure your plot has a clear title, axis labels and legend. (4 points)**

```{r}
# create plot object
p3 <- ames2 %>%
  ggplot(
    mapping =(aes(
      x = Gr_Liv_Area,
      y = Lot_Area,
      col = MS_Zoning,
    ))
  )

# make histogram
p3 + geom_point(alpha = 0.3) +
  # add titles etc
  labs(
    title = "Relationship between living area and lot area",
    x = "Living area (square feet)",
    y = "Lot area (square feet)"
  ) +
  # improve scaling
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  # improve aesthetics
  theme(
    panel.grid.major.x  = element_line(colour = "grey80"),
    axis.line.y  = element_line(colour = "black")
  ) +
  labs(color='Zone')
```


**e. Choose an appropriate plot to investigate the relationship between Garage_Cars and Lot_Area in Ames2. Use the “jitter” command to make your plot more clear. (3 points)**

```{r}
# change garage_cars to factor
#ames2$Garage_Cars <- as.factor(ames2$Garage_Cars)

# create plot object
p4 <- ames2 %>%
  ggplot(
    mapping = aes(
      x = as.factor(Garage_Cars),
      y = Lot_Area,
    )
  )

# add points
p4 + geom_jitter(alpha=0.7, colour = "grey80") +
  # add box plot
  geom_boxplot(mapping=aes(fill=as.factor(Garage_Cars)),alpha=0.8) +
  # add titles etc
  labs(
    title = "Relationship between garage car capacity and lot area",
    x = "Garage car capacity",
    y = "Lot area (square feet)"
  ) +
  # improve scaling
  scale_y_continuous(expand = c(0, 0)) +
  # improve aesthetics
  theme(
    panel.grid.major.x  = element_line(colour = "grey80"),
    axis.line.y  = element_line(colour = "black"),
    legend.position = "none"
  )
```


**f. Why do we make these plots? Comment on your findings from these plots (1 sentence is fine). (2 points)**

These plots are useful for exploring the data, so that we can see any outliers as well as seeing if there are any relationships that are worth investigating.

**g. Use the lm command to build a linear model, linmod1, of Lot_Area as a function of the predictors MS_Zoning and Gr_Liv_Area for the Ames2 dataset. Evaluate the assumptions of the model. (5 points)**
```{r}
# build model
linmod1 <- lm(Lot_Area ~ MS_Zoning + Gr_Liv_Area, 
              family=gaussian, 
              data=ames2) 
# view model
linmod1
summary(linmod1)
```

```{r}
# evaluate suitability of model

# plot residuals vs lot area
plot(linmod1$fitted,linmod1$residuals, main="Residuals vs predicted values")
abline(h=0,col=2)
```


This plot shows that the residuals are spread pretty evenly around the zero line.

```{r}
# further evaluation

# do histogram of resisuals
hist(linmod1$residuals)
```

The histogram of the residuals does look roughly like a guassian curve. It is a bit skewed though, with a longer tail on the right hand side.

```{r}
# do qq plot
qqnorm(linmod1$residual)

# add line with sd of residuals
abline(0,sd(linmod1$residuals),col=2)
```

The normal q-q plot looks like somewhat of a straight line in the middle, but at either end it does go a bit wonky, especially on the right hand side.

To investigate this further, we should try plotting the residuals against Gr_Liv_Area and against the different levels of MS_Zoning.

```{r}
# plot residuals vs GR_Liv_Area
plot(ames2$Gr_Liv_Area,linmod1$residuals,main="residuals vs GR_Liv_Area")
abline(h=0,col=2)
```

This looks decent again, though the residuals are larger above the zero line than below.

```{r}
plot(ames2$MS_Zoning,linmod1$residuals,main="residuals vs GR_Liv_Area", las=2, cex.axis=0.7)
```

This graph shows that the spread of residuals is pretty even, apart from for Residential_Low_Density. Predictions using this factor level will be less accurate than with other levels.

Overall, the model is pretty good, though there may be some issues when predicting properties with MS_Zoning == Residential_Low_Density.

**h. Use the lm command to build a second linear model, linmod2, for Lot_Area as a function of MS_Zoning, Gr_Liv_Area and Garage_Cars. (2 points)**

```{r}
# build model
linmod2 <- lm(Lot_Area ~ MS_Zoning + Gr_Liv_Area + Garage_Cars, 
              family=gaussian, 
              data=ames2) 

# view models
linmod2

summary(linmod2)
```


**i. Use Anova and Adjusted R-squared to compare these two models, and decide which is a better model. (3 points)**

```{r}
# anova for first model
Anova(linmod1)

# anova for second model
Anova(linmod2)
```

From the ANOVA we see that, in both models, MS_Zoning and Gr_Liv_Area are strongly significant predictors of Lot_Area. In the second model, Garage_Cars is also a significant predictor of Lot_Area, though not as strong as the other two variables. The residuals have been reduced slightly also, though not by a great deal.

```{r}
# summarise models again to get r^2 values
summary(linmod1)

summary(linmod2)
```

The first model has an adjusted R-squared of 0.3081, and so explains **30.8%** of variance.

The second model has an adjusted R-squared of 0.3103, and so explains **31.0%** of variance.

The second model is slightly better, though the difference between the models is almost negligible.

**j. Construct a confidence interval and a prediction interval for the lot area of a residential property in the High Density zone, with a 2 car garage and a living area of 1000 sq ft. Explain what these two intervals mean. (4 points)**

```{r}
confint(linmod2)
```

```{r}
# get confidence intervals
predict(linmod2,
        data.frame(MS_Zoning="Residential_High_Density",
                            Gr_Liv_Area=1000,
                            Garage_Cars=2), interval="confidence")

# get prediction intervals
predict(linmod2,
        data.frame(MS_Zoning="Residential_High_Density",
                            Gr_Liv_Area=1000,
                            Garage_Cars=2), interval="prediction")
```

The 95% confidence interval for this predicted lot area is 5103 to 7575 square feet. This means that there is a 95% chance that the average property in the High Density zone, with a 2 car garage, and a living area of 1000 sq ft will have a lot area between 5103 and 7575 square feet.

The 95% prediction interval for this predicted lot area is -89.76 to 12770 square feet. This means that 95% of properties in the High Density zone, with a 2 car garage, and a living area of 1000 sq ft will have a lot area between -89.76 and 12770 square feet. Obviously, it is impossible to have a negative lot area, so this model has some room for improvement.

**k. Now use the lmer function to build a third model, mmod1, for Lot_Area as a function of zoning, living area, garage size and neighborhood. What is the critical number to pull out from this, and what does it tell us? (3 points)**

```{r}
# create model
mmod1 <- lmer(Lot_Area ~ MS_Zoning + Gr_Liv_Area + Garage_Cars + 
                (1|Neighborhood), data=ames2)

# view model
mmod1
```

The most critical number to pull out of this is the standard deviation of the effect of neighborhood, which is 2632. This tells us that there is 2632 square feet of standard deviation which is caused by the area that the property is in.

**l. Construct 95% confidence intervals around each parameter estimate for mmod1. What does this tell us about the importance of the random effect? (2 points)**

```{r}
# get confidence intervals
confint(mmod1)
```

These confidence intervals show that the random effect of neighborhood is an important predictor of lot area. The confidence interval for the random effect is smaller than for other predictors, and there is a 97.5% chance that the coefficient for the random effect is greater than 1970. We can be pretty sure that neighborhood is an important predictor of lot area.

**m. Write out the full mathematical expression for the model in linmod2 and for the model in mmod1. You may round to the nearest integer in all coefficients. (4 points)**

```{r}
# get standard deviation of linmod2
sd(linmod2$residuals)
```


*linmod2:*

\begin{align*}
{\rm Lot\_Area} \sim & N(1759 + \\
& 1356 \times  {\rm MS\_ZoningResidential\_High\_Density} + \\
& 4141 \times  {\rm MS\_ZoningResidential\_Low\_Density} + \\
& 725 \times  {\rm MS\_ZoningResidential\_Medium\_Density} + \\
& 3 \times  {\rm Gr\_Liv\_Area} + \\
& 297 \times  {\rm Garage\_Cars}, \\
& 3215)
\end{align*}


*mmod1:*

\begin{align*}
{\rm Lot\_Area} \sim & N(743 + \\
& 2038 \times  {\rm MS\_ZoningResidential\_High\_Density} + \\
& 3903 \times  {\rm MS\_ZoningResidential\_Low\_Density} + \\
& 335 \times  {\rm MS\_ZoningResidential\_Medium\_Density} + \\
& 3 \times  {\rm Gr\_Liv\_Area} + \\
& 614 \times  {\rm Garage\_Cars} + \\
& N(0, 2632),\\
& 2884)
\end{align*}

# 3. Logistic Regression

**a. Construct a logistic regression model glmod1 for “played” as a function of player age and position. (2 points)**

```{r}
# I used 'playerstats' variable here, as 'football' and 'footballngk' only contain 
# players where 'played'==TRUE

# change 'position' to factor
playerstats$position <- as.factor(playerstats$position)

# construct model
poissonmod1 <- glm(played ~ age + position, family=binomial, data=playerstats)

# view model
poissonmod1
```

It makes sense that goalkeepers here are less likely to have played than other positions. Goalkeepers are rotated a lot less often than other positions, and so it is unsurprising that a lot of goalkeepers didn't play at all. It is also unsurprising players were more likely to play if they were older: there were probably quite a few youth players who didn't play at all.

```{r}
# bar chart showing proportion of players who played for each age
p5 <- playerstats %>%
  group_by(age) %>%
  summarise(playedtrue = sum(played==TRUE),
            totalage=n(),
            proportion = playedtrue/totalage) %>%
  ggplot(
    mapping = aes(
      x = age,
      y = proportion
    )
  )

# show barchart
p5 + geom_bar(stat="identity")
```

This bar chart shows a rough trend, that players get more likely to play from the age of 20 to 24, and then this plateau's somewhat.

**b. Construct confidence bands for the variable played as a function of age for each position (hint: create a new data frame for each position). Colour these with different tranparent colours for each position and plot them together on the same axes. Put the actual data on the plot, coloured to match the bands, and jittered in position to make it possible to see all points. Ensure you have an informative main plot title, axes labels and a legend. (6 points)**

```{r}
# make new dataframes for each position
goalkeepers <- playerstats %>%
  filter(position=='Goalkeeper')

defenders <- playerstats %>%
  filter(position=='Defender')

midfielders <- playerstats %>%
  filter(position=='Midfielder')

forwards <- playerstats %>%
  filter(position=='Forward')
```

```{r}
# create new model for each position
pmod_g <- glm(played ~ age, family=binomial, data=goalkeepers)
pmod_g

pmod_d <- glm(played ~ age, family=binomial, data=defenders)
pmod_d

pmod_m <- glm(played ~ age, family=binomial, data=midfielders)
pmod_m

pmod_f <- glm(played ~ age, family=binomial, data=forwards)
pmod_f
```

```{r}
# get confidence intervals for each position in previous lm
confint(pmod_g)
confint(pmod_d)
confint(pmod_m)
confint(pmod_f)
```


```{r}
# make variable for prediction, CI, etc for goalkeepers
ilinkg <-family(pmod_g)$linkinv
newplayed_g <- with(goalkeepers,
                  data.frame(age=seq(min(goalkeepers$age),
                                            max(goalkeepers$age), 
                                            length=length(
                                              unique(goalkeepers$age)))))
# get predictions for each age
newplayed_g <- cbind(newplayed_g,
                   predict(pmod_g,
                           newplayed_g,
                           type="link",
                           se.fit=TRUE)[1:2])
# get CI's for each age
newplayed_g <- transform(newplayed_g,
                       Fitted=ilinkg(fit),
                       Upper=ilinkg(fit+(1.96*se.fit)),
                       Lower=ilinkg(fit-(1.96*se.fit)))

```

```{r}
# make variable for prediction, CI, etc for defenders
ilinkd <-family(pmod_d)$linkinv
newplayed_d <- with(defenders,
                  data.frame(age=seq(min(defenders$age),
                                            max(defenders$age), 
                                            length=length(
                                              unique(defenders$age)))))
# get predictions for each age
newplayed_d <- cbind(newplayed_d,
                   predict(pmod_d,
                           newplayed_d,
                           type="link",
                           se.fit=TRUE)[1:2])
# get CI's for each age
newplayed_d <- transform(newplayed_d,
                       Fitted=ilinkd(fit),
                       Upper=ilinkd(fit+(1.96*se.fit)),
                       Lower=ilinkd(fit-(1.96*se.fit)))
```

```{r}
# make variable for prediction, CI, etc for midfielders
ilinkm <-family(pmod_m)$linkinv
newplayed_m <- with(midfielders,
                  data.frame(age=seq(min(midfielders$age),
                                            max(midfielders$age), 
                                            length=length(
                                              unique(midfielders$age)))))
# get predictions for each age
newplayed_m <- cbind(newplayed_m,
                   predict(pmod_m,
                           newplayed_m,
                           type="link",
                           se.fit=TRUE)[1:2])
# get CI's for each age
newplayed_m <- transform(newplayed_m,
                       Fitted=ilinkm(fit),
                       Upper=ilinkm(fit+(1.96*se.fit)),
                       Lower=ilinkm(fit-(1.96*se.fit)))
```

```{r}
# make variable for prediction, CI, etc for forwards
ilinkf <-family(pmod_f)$linkinv
newplayed_f <- with(forwards,
                  data.frame(age=seq(min(forwards$age),
                                            max(forwards$age), 
                                            length=length(
                                              unique(forwards$age)))))
# get predictions for each age
newplayed_f <- cbind(newplayed_f,
                   predict(pmod_f,
                           newplayed_f,
                           type="link",
                           se.fit=TRUE)[1:2])
# get CI's for each age
newplayed_f <- transform(newplayed_f,
                       Fitted=ilinkf(fit),
                       Upper=ilinkf(fit+(1.96*se.fit)),
                       Lower=ilinkf(fit-(1.96*se.fit)))
```

```{r}
# make plot object
p6 <-ggplot(playerstats,
       aes(x=age,
           y=as.numeric(played))) +
  # add labesl and title
  labs(title = "How likely players in each position are to have \n played depending on their age",
       y = "Probability played",
       x = "Age",
       colour='Legend') +
  # improve aesthetics
  theme(axis.line.y  = element_line(colour = "black")) +
  # scale to make predictions after jitter stay between 0 and 1
  scale_y_continuous(limits = c(0, 1), oob = scales::squish)

p6 +  
  
  # add goalkeeper prediction line
  geom_line(data = newplayed_g,
            aes(y = Fitted,
                x = age),
            colour="green") +
  # add CI's
  geom_ribbon(data = newplayed_g,
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "green",
              alpha = 0.2,
              inherit.aes = FALSE) +
  # add prediction for each age
  geom_point(data = goalkeepers,
             position = position_jitter(w=0, h=0.08), 
             colour="green",
             alpha=0.4) +

  
  
  # add defender prediction line
  geom_line(data = newplayed_d,
            aes(y = Fitted,
                x = age),
            colour="yellow") +
  # add CI's
  geom_ribbon(data = newplayed_d,
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "yellow",
              alpha = 0.2,
              inherit.aes = FALSE) +
  # add prediction for each age
  geom_point(data = defenders,
             position = position_jitter(w=0, h=0.08), 
             colour="yellow",
             alpha=0.4) +
    
  
  
  # add midfielder prediction line
  geom_line(data = newplayed_m,
            aes(y = Fitted,
                x = age),
            colour="blue") +
  # add CI's
  geom_ribbon(data = newplayed_m,
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "blue",
              alpha = 0.2,
              inherit.aes = FALSE) +
  # add prediction for each age
  geom_point(data = midfielders,
             position = position_jitter(w=0, h=0.08), 
             colour="blue",
             alpha=0.4) +



  # add forward prediction line
  geom_line(data = newplayed_f,
            aes(y = Fitted,
                x = age),
            colour="red") +
  # add CI's
  geom_ribbon(data = newplayed_f,
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "red",
              alpha = 0.2,
              inherit.aes = FALSE) +
  # add prediction for each age
  geom_point(data = forwards,
             position = position_jitter(w=0, h=0.1), 
             colour="red",
             alpha=0.4) +
  
    labs(title = "How likely players in each position are to have \n played depending on their age",
       y = "Probability played",
       x = "Age",
       colour='Legend')

```

I'm not sure how to add a legend to the graph above. I looked online, and it seems as though I'll have to make a dataframe containing all the players to be able to do this.

```{r}
# so that i can add a legend to the plot, i will make a new dataframe containing
# the predictions and CI's for each position

# first, create a new dataframe for each position
newdf_g <- data.frame(newplayed_g)
newdf_g$position <- "Goalkeeper"

newdf_d <- data.frame(newplayed_d)
newdf_d$position <- "Defender"

newdf_m <- data.frame(newplayed_m)
newdf_m$position <- "Midfielder"

newdf_f <- data.frame(newplayed_f)
newdf_f$position <- "Forward"

# concatenate these dtaframes
newdf <- rbind(newdf_g, newdf_d, newdf_m, newdf_f)

```


```{r}
# now, do the same as before but with newdf

p7 <-ggplot(playerstats,
       aes(x=age,
           y=as.numeric(played),
           colour=position)) +
  # add labesl and title
  labs(title = "How likely players in each position are to have \n played, depending on their age",
       subtitle = "(attempt 2)",
       y = "Probability played",
       x = "Age",
       colour='Position') +
  # improve aesthetics
  theme(axis.line.y  = element_line(colour = "black"))
  # # scale to make predictions after jitter stay between 0 and 1
  # scale_y_continuous(limits = c(0, 1), oob = scales::squish)

p7 +
  #customize scale colours
  scale_color_manual(values=c("darkorange1",
                              "darkolivegreen2",
                              "lightskyblue",
                              "darkorchid2")) +
  
  # add prediction lines
  geom_line(data = newdf,
            aes(y = Fitted,
                x = age)) +
  
  # add prediction for each age
  geom_point(data = playerstats,
             position = position_jitter(w=0, h=0.08),
             alpha=0.5) +


# add CI's for goalkeepers
  geom_ribbon(data = newdf[newdf$position=="Goalkeeper",],
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "lightskyblue",
              alpha = 0.2,
              inherit.aes = FALSE) +

# add CI's for defenders
  geom_ribbon(data = newdf[newdf$position=="Defender",],
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "darkorange1",
              alpha = 0.2,
              inherit.aes = FALSE) +
  
  
# add CI's for midfielders
  geom_ribbon(data = newdf[newdf$position=="Midfielder",],
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "darkorchid2",
              alpha = 0.2,
              inherit.aes = FALSE) +


# add CI's for forwards
  geom_ribbon(data = newdf[newdf$position=="Forward",],
              aes(ymin = Lower,
                  ymax = Upper,
                  x = age),
              fill = "darkolivegreen2",
              alpha = 0.2,
              inherit.aes = FALSE) 


```

**c. Split the data using set.seed(123) and rebuild the model on 70% of the data. Cross validate on the remaining 30%. Plot the ROCs for both data and comment on your findings. (6 points)**

```{r}
# set seed
set.seed(123) 

# split data 70:30
training_samples <- playerstats$played %>% 
  createDataPartition(p = 0.7, list = FALSE) 
train_data <- playerstats[training_samples, ]
test_data <- playerstats[-training_samples, ]
```

```{r}
# train model
train_model <- glm(played ~ age + position,
                   family = binomial,
                   data = train_data)
```

```{r}
# make predictions with training data
predtrain<-predict(train_model,type="response")

# make predictions with test data
predtest<-predict(train_model,newdata=test_data,type="response")

# show ROC curve for training data
roctrain<-roc(response=train_data$played,
              predictor=predtrain,
              plot=TRUE,
              main="ROC Curve for prediction of whether a player has played",
              auc=TRUE)

# adfd ROC curve for testing data
roc(response=test_data$played,
    predictor=predtest,
    plot=TRUE,
    auc=TRUE,
    add=TRUE,
    col="red")

legend(0, 0.4,legend=c("Training","Testing"),fill=1:2)
```

The ROC curves look pretty similar in shape, though there are some small gaps. The model doesn't appear to be massively overfitted to the training data.

# 4. Multinomial Regression

**a. For the dataset footballngk, create a model multregmod to predict position from goals_per_90_overall, assists_per_90_overall, conceded_per_90_overall and cards_per_90_overall. (2 points)**

```{r}
# create model
multregmod <- multinom(position ~ goals_per_90_overall +
                         assists_per_90_overall +
                         conceded_per_90_overall +
                         cards_per_90_overall,
                       data = footballngk)

# view model
multregmod
```


**b. Write out the formulas for this model in terms of P(Forward) and P(Midfielder). You may round coefficients to 2 digits. All other factors equal, what position is a player with more assists more likely to play? (5 points)**


\begin{align*}
{\rm P(Forward)} \sim & N(-2.4 + \\
& 9.6 \times  {\rm goals\_per\_90\_overall } + \\
& 3.9 \times  {\rm assists\_per\_90\_overall} + \\
& 0.33 \times  {\rm conceded\_per\_90\_overall } - \\
& 0.030 \times  {\rm cards\_per\_90\_overall}
\end{align*}

\begin{align*}
{\rm P(Midfielder)} \sim & N(-0.45 + \\
& 4.8 \times  {\rm goals\_per\_90\_overall } + \\
& 2.8 \times  {\rm assists\_per\_90\_overall} + \\
& 0.047 \times  {\rm conceded\_per\_90\_overall } + \\
& 0.0093 \times  {\rm cards\_per\_90\_overall}
\end{align*}

All other factors equal, a player with more assists is more likely to play as a forward

**c. Evaluate the performance of this model using a confusion matrix and by calculating the sum of sensitivities for the model. Comment on your findings. (3 points)**

```{r}
# make confusion matrix
multitable <- table(footballngk$position,
                    predict(multregmod,
                            type="class"))
# add column names for clarity
names(dimnames(multitable)) <- list("Actual",
                                    "Predicted") 
# view confusion matrix
multitable
```

```{r}
# calculate sum of sensitivities
SSens <- multitable[1,1]/sum(footballngk$position=="Defender") +
  multitable[2,2]/sum(footballngk$position=="Forward") +
  multitable[3,3]/sum(footballngk$position=="Midfielder")
SSens

# get average sum of sensitivities per position
mean_SSens <- SSens/3

mean_SSens
```

The model predicts about 54% of players' positions correctly. The model seems to predict a lot of defenders as midfielders. This could be because some positions in defense are allowed more freedom to go forward, and so may get similar stats to some midfielders.
The opposite is also true, and this is likely to be because some midfielders are more defensive and will therefore have similar stats to some defenders.

Similar is true of forwards: some forwards are involved more in the build-up play and so may get more similar stats to midfielders or even defenders, causing them to be classified incorrectly.

Also, the categories of defender, midfielder, and forward are pretty broad, and with more precise position labels such as striker, winger, or full-back we may get more accurate predictions of position. 

# 5. Poisson/quasipoisson Regression

**a. For the football dataset, first create a variable indicating the total number of all cards a player received overall. Then create a model countmod to predict the total number of cards a player received based on position and appearances. (3 points)**

```{r}
# make total_cards variable
football$total_cards <- football$yellow_cards_overall +
  football$red_cards_overall

# change position to factor
football$position <- as.factor(football$position)
```

```{r}
# generate model
countmod <- glm(total_cards ~ position +
                  appearances_overall, 
                data = football,
                family = "poisson")

# show model
summary(countmod)
```



**b. Check the assumption of the model using a diagnostic plot and comment on your findings. (2 points)**

```{r}
# to evaluate dispersion assumption, plot abs value of residuals vs predicted means
plot(countmod,which=3) 
abline(h=0.8,col=3)
```

The mean dispersion is not completely flat, but is pretty close to 0.8. The plot does show slight overdispersion, which increases as the prediction increases. It would probably be better to use a quasipoisson model which does not assume dispersion to be equal to the mean.

```{r}
# try building a quasipoisson model
quasicountmod <- glm(total_cards ~ position +
                  appearances_overall, 
                data = football,
                family = "quasipoisson")

# show model
summary(quasicountmod)
```

In the quasipoisson model, the dispersion parameter is estimated at 1.67 instead of 1, confirming overdispersion in the previous model.

**c. What do the coefficients of the model tell us about which position gets the most cards? For the same minutes of play, how many times more cards do they get than the position that gets the least cards? (3 points)**

As defender was the baseline factor coefficient in the model, and all other position coefficients were negative, the coefficients show that **defenders tend to get the most cards**.

For the second part of the question, we should build a new model using minutes played to predict total cards received, as the previous model used appearances rather than minutes played.

```{r}
# build new model with minutes played instead of appearances
countmod2 <- glm(total_cards ~ position +
                  minutes_played_overall, 
                data = football,
                family = "quasipoisson")

# show model
countmod2
```

```{r}
# make predictions to compare midfielders (most cards per minute) to goalkeepers (least cards per minute)

# goalkeeper
gk_cards <- predict(countmod2,
        newdata = data.frame(position="Goalkeeper",
                                      minutes_played_overall=1000),
        type = "response")

# midfielder
mf_cards <- predict(countmod2,
        newdata = data.frame(position="Midfielder",
                                      minutes_played_overall=1000), 
        type = "response")

mf_cards / gk_cards
```


For the same number of minutes played, midfielders get **6.2** times as many cards as goalkeepers do.
